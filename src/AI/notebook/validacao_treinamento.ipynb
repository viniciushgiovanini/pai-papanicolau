{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"./model/modelo_treinado_teste_100.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metodo de classificacao CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "[0.4414954]\n",
      "Positivo\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def classficar(img, isBinario):\n",
    "\n",
    "  \n",
    "  model = load_model(\"./model/modelo_treinado_teste_100.h5\")\n",
    "  \n",
    "  img = img.resize((100,100))\n",
    "  # plt.imshow(img)\n",
    "  # plt.show()\n",
    "  \n",
    "  x = image.img_to_array(img)\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "  images = np.vstack([x])\n",
    "  value = model.predict(images)\n",
    "  print(value[0])\n",
    "  value = value[0].tolist()\n",
    "  \n",
    "  value_list_int = list(map(int, value))         \n",
    "  \n",
    "  maxValue = max(value_list_int)        \n",
    "  valu_posi = value_list_int.index(maxValue)\n",
    "  \n",
    "  if(isBinario):\n",
    "    if value[0] > 0.85:\n",
    "        return \"Negativo\"\n",
    "    else:\n",
    "        return \"Positivo\"\n",
    "  else:\n",
    "    dictClassifier = {\"ASC-H\": 0, \"ASC-US\" : 1, \"HSIL\": 2, \"LSIL\": 3, \"Negative\": 4, \"SCC\": 5}\n",
    "    for i,each in enumerate(dictClassifier):\n",
    "      \n",
    "      if(valu_posi == i):\n",
    "        return each\n",
    "      \n",
    "img = image.load_img(\"../data/cnn_treino_binario/train/Negative for intraepithelial lesion/5.png\")\n",
    "print(classficar(img, True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificacao Mahanalobis Binario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def calculaAreaPerimetroImagem(img_cv2):\n",
    "  \n",
    "  imagem_cinza = cv2.cvtColor(img_cv2, cv2.COLOR_BGR2GRAY)\n",
    "  _, mascara_binaria = cv2.threshold(imagem_cinza, 1, 255, cv2.THRESH_BINARY)\n",
    "  contornos, _ = cv2.findContours(mascara_binaria, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "  mascara_colorida = np.zeros_like(img_cv2)\n",
    "  cv2.drawContours(mascara_colorida, contornos, -1, (255, 255, 255), thickness=cv2.FILLED)\n",
    "\n",
    "  area_branca = np.sum(mascara_binaria == 255)\n",
    "  \n",
    "  \n",
    "  total_perimetro = 0\n",
    "  \n",
    "  for contorno in contornos:\n",
    "    perimeter = cv2.arcLength(contorno, closed=True)\n",
    "    total_perimetro += perimeter\n",
    "  \n",
    "  return area_branca, round(total_perimetro, 2)\n",
    "\n",
    "\n",
    "\n",
    "# perimetro^2 / 4 PI area\n",
    "def calcularCompacidade(img_cv2):\n",
    "  area, perimetro = calculaAreaPerimetroImagem(img_cv2)\n",
    "  \n",
    "  compacidade = (perimetro**2) / (area * (4 * math.pi)) \n",
    "  \n",
    "  return round(compacidade, 4)\n",
    "\n",
    "\n",
    "\n",
    "def calcularExcentricidades(img_cv2):\n",
    "  \n",
    "  imagem_cinza = cv2.cvtColor(img_cv2, cv2.COLOR_BGR2GRAY)\n",
    "  _, mascara_binaria = cv2.threshold(imagem_cinza, 1, 255, cv2.THRESH_BINARY)\n",
    "  contornos, _ = cv2.findContours(mascara_binaria, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "  maior_contorno = max(contornos, key=cv2.contourArea)\n",
    "\n",
    "    \n",
    "  if len(maior_contorno) >= 5:\n",
    "    elipse = cv2.fitEllipse(maior_contorno)\n",
    "    eixo_maior = max(elipse[1])\n",
    "    eixo_menor = min(elipse[1])\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "\n",
    "  # Calcular excentricidade\n",
    "  # 1-menor^2 / 1-maior^2\n",
    "  \n",
    "  excentricidade = 1 - ((eixo_menor ** 2) / (eixo_maior ** 2))\n",
    "  \n",
    "  \n",
    "  \n",
    "  return excentricidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import mahalanobis\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "\n",
    "def calcular_estatisticas_por_classe(df):\n",
    "    estatisticas_por_classe = {}\n",
    "    for classe in df['label'].unique():\n",
    "        classe_df = df[df['label'] == classe]\n",
    "        \n",
    "        # Converta as colunas para n√∫meros\n",
    "        numeric_columns = ['area', 'compacidade', 'excentricidade']\n",
    "        for col in numeric_columns:\n",
    "            classe_df[col] = pd.to_numeric(classe_df[col], errors='coerce')\n",
    "        \n",
    "        estatisticas_por_classe[classe] = {\n",
    "            'media': np.mean(classe_df[numeric_columns], axis=0),\n",
    "            'covariancia': np.cov(classe_df[numeric_columns], rowvar=False)\n",
    "        }\n",
    "    return estatisticas_por_classe\n",
    "\n",
    "\n",
    "def gerarEstatisticas(path_csv):\n",
    "  \n",
    "  df = pd.read_csv(path_csv)\n",
    "  train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "  estatisticas_treinamento = calcular_estatisticas_por_classe(train_df)\n",
    "  return estatisticas_treinamento\n",
    "  \n",
    "  \n",
    "def classificar_mahalanobis(amostra, estatisticas_por_classe):\n",
    "    distancias = {}\n",
    "    for classe, estatisticas in estatisticas_por_classe.items():\n",
    "        distancias[classe] = mahalanobis(amostra, estatisticas['media'], np.linalg.inv(estatisticas['covariancia']))\n",
    "    return min(distancias, key=distancias.get)\n",
    "\n",
    "\n",
    "    \n",
    "  \n",
    "def classificarMahalanobis(img):\n",
    "  area, _ = calculaAreaPerimetroImagem(img)\n",
    "  compacidade = calcularCompacidade(img)\n",
    "  excentricidade = calcularExcentricidades(img)\n",
    "\n",
    "  amostra = np.array([area, compacidade, excentricidade])\n",
    "  predicao = classificar_mahalanobis(amostra, gerarEstatisticas(\"../../csv_pt2_binario.csv\"))\n",
    "  print(predicao)\n",
    "\n",
    "img = cv2.imread(\"../../data/segmentation_dataset_binario/Positivo/1.png\")\n",
    "classificarMahalanobis(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
